"""
AI-powered clothing analysis using Google Gemini Vision
"""
import google.generativeai as genai
import json
import logging
from typing import Dict, Optional
from io import BytesIO

logger = logging.getLogger(__name__)

# Initialize Gemini
def init_gemini(api_key: str):
    if not api_key:
        logger.warning("Gemini API Key missing. AI features disabled.")
        return
    genai.configure(api_key=api_key)
    
    # Log available models
    try:
        for model in genai.list_models():
            if 'generateContent' in model.supported_generation_methods:
                logger.info(f"Available Gemini model: {model.name}")
    except Exception as e:
        logger.error(f"Could not list models: {e}")

async def analyze_clothing_photo(photo_bytes: bytes) -> Dict:
    """
    Analyze clothing photo using Gemini Vision with automatic model fallback
    """
    import PIL.Image
    
    # Prepare image
    try:
        image = PIL.Image.open(BytesIO(photo_bytes))
    except Exception as e:
        return {'success': False, 'error': f"Image load error: {e}"}

    # Prompt
    prompt = """
    ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ ÑÑ‚Ñƒ Ğ¾Ğ´ĞµĞ¶Ğ´Ñƒ Ğ¸ Ğ¾Ğ¿Ğ¸ÑˆĞ¸:
    1. Ğ¢Ğ¸Ğ¿ Ğ¾Ğ´ĞµĞ¶Ğ´Ñ‹ (Ñ„ÑƒÑ‚Ğ±Ğ¾Ğ»ĞºĞ°, ĞºÑƒÑ€Ñ‚ĞºĞ°, ÑĞ²Ğ¸Ñ‚ĞµÑ€, Ğ´Ğ¶Ğ¸Ğ½ÑÑ‹ Ğ¸ Ñ‚.Ğ´.)
    2. ĞœĞ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ» (ĞµÑĞ»Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ½: Ñ…Ğ»Ğ¾Ğ¿Ğ¾Ğº, ÑˆĞµÑ€ÑÑ‚ÑŒ, ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸ĞºĞ°, Ğ´Ğ¶Ğ¸Ğ½ÑĞ°)
    3. Ğ¡Ñ‚ĞµĞ¿ĞµĞ½ÑŒ Ñ‚ĞµĞ¿Ğ»Ğ¾Ñ‚Ñ‹: Ğ»ĞµĞ³ĞºĞ°Ñ/ÑÑ€ĞµĞ´Ğ½ÑÑ/Ñ‚ĞµĞ¿Ğ»Ğ°Ñ/Ğ¾Ñ‡ĞµĞ½ÑŒ Ñ‚ĞµĞ¿Ğ»Ğ°Ñ
    4. ĞŸĞ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¹ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ½Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ² Â°C (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: Ğ¾Ñ‚ 15 Ğ´Ğ¾ 25)
    5. Ğ¡Ñ‚Ğ¸Ğ»ÑŒ: casual/formal/sport
    
    ĞÑ‚Ğ²ĞµÑ‚ÑŒ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ JSON Ğ±ĞµĞ· Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ°:
    {
      "clothing_type": "Ñ‚Ğ¸Ğ¿ Ğ¾Ğ´ĞµĞ¶Ğ´Ñ‹",
      "material": "Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ» Ğ¸Ğ»Ğ¸ Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾",
      "warmth_level": "Ğ»ĞµĞ³ĞºĞ°Ñ|ÑÑ€ĞµĞ´Ğ½ÑÑ|Ñ‚ĞµĞ¿Ğ»Ğ°Ñ|Ğ¾Ñ‡ĞµĞ½ÑŒ Ñ‚ĞµĞ¿Ğ»Ğ°Ñ",
      "suitable_temp_min": Ñ‡Ğ¸ÑĞ»Ğ¾,
      "suitable_temp_max": Ñ‡Ğ¸ÑĞ»Ğ¾,
      "style": "casual|formal|sport",
      "description": "ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼"
    }
    """

    # List of models to try in order
    # Using 'latest' aliases where appropriate or strictly known working models
    candidates = [
        'gemini-1.5-flash',
        'gemini-1.5-flash-latest',
        'gemini-1.5-pro',
        'gemini-1.5-pro-latest',
    ]

    last_error = None
    
    for model_name in candidates:
        try:
            logger.info(f"Attempting analysis with model: {model_name}")
            model = genai.GenerativeModel(model_name)
            
            # This is the actual network call that might fail
            response = model.generate_content([prompt, image])
            
            # Parse JSON
            response_text = response.text.strip()
            if response_text.startswith('```'):
                response_text = response_text.split('```')[1]
                if response_text.startswith('json'):
                    response_text = response_text[4:]
            
            data = json.loads(response_text)
            data['success'] = True
            logger.info(f"Success with model: {model_name}")
            return data
            
        except Exception as e:
            logger.warning(f"Model {model_name} failed: {e}")
            last_error = e
            continue
    
    logger.error("All Gemini models failed")
    return {
        'success': False,
        'error': f"AI Analysis failed. Last error: {str(last_error)}"
    }

async def analyze_clothing_text(text_description: str) -> Dict:
    """
    Analyze clothing based on text description using Gemini
    """
    prompt = f"""
    ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ ÑÑ‚Ğ¾ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¾Ğ´ĞµĞ¶Ğ´Ñ‹: "{text_description}"
    
    ĞĞ¿Ğ¸ÑˆĞ¸:
    1. Ğ¢Ğ¸Ğ¿ Ğ¾Ğ´ĞµĞ¶Ğ´Ñ‹ (Ñ„ÑƒÑ‚Ğ±Ğ¾Ğ»ĞºĞ°, ĞºÑƒÑ€Ñ‚ĞºĞ°, ÑĞ²Ğ¸Ñ‚ĞµÑ€, Ğ´Ğ¶Ğ¸Ğ½ÑÑ‹ Ğ¸ Ñ‚.Ğ´.)
    2. ĞœĞ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ» (Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸ Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ñƒ, ĞµÑĞ»Ğ¸ Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½)
    3. Ğ¡Ñ‚ĞµĞ¿ĞµĞ½ÑŒ Ñ‚ĞµĞ¿Ğ»Ğ¾Ñ‚Ñ‹: Ğ»ĞµĞ³ĞºĞ°Ñ/ÑÑ€ĞµĞ´Ğ½ÑÑ/Ñ‚ĞµĞ¿Ğ»Ğ°Ñ/Ğ¾Ñ‡ĞµĞ½ÑŒ Ñ‚ĞµĞ¿Ğ»Ğ°Ñ
    4. ĞŸĞ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¹ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ½Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ² Â°C (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: Ğ¾Ñ‚ 15 Ğ´Ğ¾ 25)
    5. Ğ¡Ñ‚Ğ¸Ğ»ÑŒ: casual/formal/sport
    
    ĞÑ‚Ğ²ĞµÑ‚ÑŒ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ JSON Ğ±ĞµĞ· Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ°:
    {{
      "clothing_type": "Ñ‚Ğ¸Ğ¿ Ğ¾Ğ´ĞµĞ¶Ğ´Ñ‹",
      "material": "Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»",
      "warmth_level": "Ğ»ĞµĞ³ĞºĞ°Ñ|ÑÑ€ĞµĞ´Ğ½ÑÑ|Ñ‚ĞµĞ¿Ğ»Ğ°Ñ|Ğ¾Ñ‡ĞµĞ½ÑŒ Ñ‚ĞµĞ¿Ğ»Ğ°Ñ",
      "suitable_temp_min": Ñ‡Ğ¸ÑĞ»Ğ¾,
      "suitable_temp_max": Ñ‡Ğ¸ÑĞ»Ğ¾,
      "style": "casual|formal|sport",
      "description": "ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼"
    }}
    """

    # Updated model list with latest aliases
    candidates = [
        'gemini-1.5-flash',
        'gemini-1.5-flash-latest',
        'gemini-1.5-pro',
        'gemini-1.5-pro-latest',
    ]
    last_error = None
    
    for model_name in candidates:
        try:
            logger.info(f"Attempting text analysis with model: {model_name}")
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            
            response_text = response.text.strip()
            if response_text.startswith('```'):
                response_text = response_text.split('```')[1]
                if response_text.startswith('json'):
                    response_text = response_text[4:]
            
            data = json.loads(response_text)
            data['success'] = True
            logger.info(f"Success with model: {model_name}")
            return data
            
        except Exception as e:
            logger.warning(f"Model {model_name} failed: {e}")
            last_error = e
            continue
            
    return {'success': False, 'error': f"Analysis failed: {str(last_error)}"}

def generate_clothing_recommendation(clothing_data: Dict, weather_data: Dict, user_name: str) -> str:
    """
    Generate recommendation message comparing clothing with weather
    """
    current_temp = weather_data['main']['temp']
    suitable_min = clothing_data.get('suitable_temp_min', -50)
    suitable_max = clothing_data.get('suitable_temp_max', 50)
    
    verdict = ""
    emoji = ""
    advice = ""

    if suitable_min <= current_temp <= suitable_max:
        verdict = 'âœ… ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¸Ñ‚!'
        emoji = 'ğŸ‘'
        advice = f'Ğ­Ñ‚Ğ° {clothing_data.get("clothing_type", "Ğ¾Ğ´ĞµĞ¶Ğ´Ğ°")} Ğ¸Ğ´ĞµĞ°Ğ»ÑŒĞ½Ğ° Ğ´Ğ»Ñ ÑĞµĞ³Ğ¾Ğ´Ğ½ÑÑˆĞ½ĞµĞ¹ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ñ‹ ({current_temp:+.0f}Â°C)!'
    
    elif current_temp < suitable_min:
        diff = suitable_min - current_temp
        verdict = 'â„ï¸ Ğ‘ÑƒĞ´ĞµÑ‚ Ñ…Ğ¾Ğ»Ğ¾Ğ´Ğ½Ğ¾'
        emoji = 'ğŸ¥¶'
        advice = f'Ğ”Ğ»Ñ {current_temp:+.0f}Â°C ÑÑ‚Ğ¾ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ»ĞµĞ³ĞºĞ¾. Ğ’Ğ°Ğ¼ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ñ…Ğ¾Ğ»Ğ¾Ğ´Ğ½Ğ¾ (Ğ½Ğ° {diff:.0f}Â°C Ñ…Ğ¾Ğ»Ğ¾Ğ´Ğ½ĞµĞµ ĞºĞ¾Ğ¼Ñ„Ğ¾Ñ€Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ°).'
        
    elif current_temp > suitable_max:
        diff = current_temp - suitable_max
        verdict = 'ğŸ”¥ Ğ‘ÑƒĞ´ĞµÑ‚ Ğ¶Ğ°Ñ€ĞºĞ¾'
        emoji = 'ğŸ¥µ'
        advice = f'ĞŸÑ€Ğ¸ {current_temp:+.0f}Â°C Ğ² ÑÑ‚Ğ¾Ğ¼ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¶Ğ°Ñ€ĞºĞ¾ (Ğ½Ğ° {diff:.0f}Â°C Ñ‚ĞµĞ¿Ğ»ĞµĞµ ĞºĞ¾Ğ¼Ñ„Ğ¾Ñ€Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ°).'

    return f"""
<b>ğŸ“¸ ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¾Ğ´ĞµĞ¶Ğ´Ñ‹</b>
ğŸ§¥ <b>Ğ¢Ğ¸Ğ¿:</b> {clothing_data.get('clothing_type')}
ğŸ§µ <b>ĞœĞ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»:</b> {clothing_data.get('material')}
ğŸŒ¡ï¸ <b>Ğ¢ĞµĞ¿Ğ»Ğ¾Ñ‚Ğ°:</b> {clothing_data.get('warmth_level')}
ğŸ“Š <b>ĞŸĞ¾Ğ´Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ´Ğ»Ñ:</b> {suitable_min}Â°C ... {suitable_max}Â°C
ğŸ‘” <b>Ğ¡Ñ‚Ğ¸Ğ»ÑŒ:</b> {clothing_data.get('style')}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
<b>{emoji} ĞŸĞ¾Ğ³Ğ¾Ğ´Ğ° ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ:</b> {current_temp:+.0f}Â°C
<b>{verdict}</b>
{advice}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ <i>{clothing_data.get('description', '')}</i>
"""
